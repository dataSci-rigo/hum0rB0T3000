{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HumorB0t3000v1",
      "provenance": [],
      "collapsed_sections": [
        "k-uR9ozU8-rl"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP1Yopoi0tRDB4e5SFSu+2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataSci-rigo/hum0rB0T3000/blob/master/HumorB0t3000v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4Yc-867TMSa",
        "colab_type": "text"
      },
      "source": [
        "# Instructions\n",
        "\n",
        "# 1. Click on the box above labeled \"open in playground.\"\n",
        "# 2. Go to Runtime in th colab menu above (between Insert and Tools) and click on Run all\n",
        "## click run anyway (I wrote this colab)\n",
        "Installing Humobor bot in colab takes about 15 minutes. So after you hit run comeback in 15 mins to see the first run.\n",
        "\n",
        "Then scroll to the bottom to see Jokes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-uR9ozU8-rl",
        "colab_type": "text"
      },
      "source": [
        "## source code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwGfeQkAqj8h",
        "colab_type": "code",
        "outputId": "79114e72-c418-4b9a-a72c-17bcec115a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -r ./apex/requirements.txt\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY_LZozqqkxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!sh setup.sh\n",
        "!git clone https://github.com/huggingface/transformers\n",
        "\n",
        "import os\n",
        "os.chdir('transformers')\n",
        "\n",
        "!python -m pip install .\n",
        "!python -m pip install -r ./examples/requirements.txt\n",
        "os.chdir('examples')\n",
        "!python -m pip install dict_to_obj\n",
        "!python -m pip install gTTS \n",
        "import boto3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "CHECKPOINT_PATH = '/content/short_jokes'\n",
        "!mkdir {CHECKPOINT_PATH}\n",
        "names= ['/short_jokes/config.json',\n",
        "'/short_jokes/merges.txt',\n",
        "'/short_jokes/pytorch_model.bin',\n",
        "'/short_jokes/special_tokens_map.json',\n",
        "'/short_jokes/tokenizer_config.json',\n",
        "'/short_jokes/training_args.bin',\n",
        "'/short_jokes/vocab.json',]\n",
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 220\n",
        "SEED = 1234\n",
        "train_ON ='/content/shuffle_short_cls.txt'\n",
        "\n",
        "\n",
        "import torch\n",
        "import run_language_modeling\n",
        "import run_generation\n",
        "from dict_to_obj import DictToObj\n",
        "import collections\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import subprocess\n",
        "#from flask import Flask, jsonify, request\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "import warnings\n",
        "import pickle\n",
        "#from apex import amp\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import BertConfig\n",
        "\n",
        "from nltk import ngrams\n",
        "import pandas as pd\n",
        "import scipy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM2F9QzXcQ9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "\n",
        "s3r_read = boto3.resource('s3', aws_access_key_id=\"AKIA32S7UTDXTRCOBC6C\",\n",
        "    aws_secret_access_key=\"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\")\n",
        "buck = s3r_read.Bucket('humorbot3000')\n",
        "\n",
        "buck.download_file('shuffle_short_cls.txt','/content/shuffle_short_cls.txt')\n",
        "\n",
        "for name in names:\n",
        "  buck.download_file(name,'/content/'+name)\n",
        "\n",
        "s3r_write = boto3.resource('s3', aws_access_key_id='AKIA32S7UTDXS2OX5FMX',\n",
        "    aws_secret_access_key='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')\n",
        "write_buck = s3r_write.Bucket('humorbot3000results')\n",
        "def tokenizer():\n",
        "    BERT_MODEL_PATH = 'bert-base-uncased'\n",
        "    return BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
        "def convert_text(text, max_seq_length,tokenizer):\n",
        "    max_seq_length -=2\n",
        "    all_tokens = []\n",
        "    longer = 0\n",
        "    tokens_a = tokenizer.tokenize(text)\n",
        "    while len(tokens_a)>max_seq_length:\n",
        "        tokens_b = tokens_a[:max_seq_length]\n",
        "        tokens_a=tokens_a[max_seq_length:]\n",
        "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_b+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_b))\n",
        "        all_tokens.append(one_token)\n",
        "    one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
        "    all_tokens.append(one_token)\n",
        "    #print(longer)\n",
        "    return np.array(all_tokens)\n",
        "\n",
        "def get_model(local_dir, model_aws_dir=None, buck=buck):\n",
        "    \n",
        "    if  model_aws_dir !=None:\n",
        "        !python -m pip install pytorch_pretrained_bert\n",
        "        #!mkdir {local_dir}\n",
        "        buck.download_file(model_aws_dir,local_dir)\n",
        "    model = torch.load(local_dir)\n",
        "    \n",
        "\n",
        "    model.to(torch.device('cpu'))\n",
        "    model.eval()\n",
        "    print(\"Model Loaded\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict_it(text,tokenizer,model):\n",
        "    sequences = convert_text(text,MAX_SEQUENCE_LENGTH,tokenizer)\n",
        "    valid_preds = np.zeros((len(sequences)))\n",
        "    #print(valid_preds.shape)\n",
        "    valid = torch.utils.data.TensorDataset(torch.tensor(sequences,dtype=torch.long))\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=1, shuffle=False)\n",
        "    #device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = torch.device('cpu')\n",
        "    for i,(x_batch,)  in enumerate(valid_loader):\n",
        "        #print(i)\n",
        "        pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        "        pred = pred[0]\n",
        "        y_soft = F.softmax(pred,dim =1)\n",
        "        valid_preds=y_soft[0].detach().cpu().squeeze().numpy()\n",
        "    return valid_preds\n",
        "def toxic_it(text,tokenizer,model):\n",
        "    sequences = convert_text(text,MAX_SEQUENCE_LENGTH,tokenizer)\n",
        "    valid_preds = np.zeros((len(sequences)))\n",
        "    #print(valid_preds.shape)\n",
        "    valid = torch.utils.data.TensorDataset(torch.tensor(sequences,dtype=torch.long))\n",
        "    valid_loader = torch.utils.data.DataLoader(valid, batch_size=1, shuffle=False)\n",
        "    device = torch.device('cpu')\n",
        "    for i,(x_batch,)  in enumerate(valid_loader):\n",
        "        #print(i)\n",
        "        pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        " \n",
        "        valid_preds=pred[0].detach().cpu().squeeze().numpy()\n",
        "    return valid_preds\n",
        "def get_embeddings(train_ON,buck,run_init=False,run_first=True):\n",
        "  if run_first:\n",
        "    os.chdir('/content/')\n",
        "    !git clone https://github.com/UKPLab/sentence-transformers/\n",
        "    os.chdir('/content/sentence-transformers')\n",
        "    !python -m pip install -e .\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "  model_sentence = SentenceTransformer('bert-base-nli-mean-tokens')\n",
        "  if run_init:\n",
        "    with open(train_ON) as f:\n",
        "        jokes_tested = f.readlines()\n",
        "    print(len(jokes_tested))\n",
        "    query_embeddings = model_sentence.encode(jokes_tested)\n",
        "    np.save('/content/query_embeddings.npy',np.array(query_embeddings))\n",
        "    buck.upload_file('/content/query_embeddings.npy', 'query_embeddings_siamese.npy')\n",
        "\n",
        "  else:\n",
        "    buck.download_file('query_embeddings_siamese.npy','/content/query_embeddings.npy', )\n",
        "    query_embeddings= np.load('/content/query_embeddings.npy',)\n",
        "  os.chdir('/content/')\n",
        "  return model_sentence, query_embeddings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "def load_model(args):\n",
        "  \"\"\"Creates a model and loads in weights for it.\"\"\"\n",
        "  \n",
        "  config = AutoConfig.from_pretrained(args.model_name_or_path, cache_dir=None)\n",
        "  #config_class, model_class, _ = run_language_modeling.MODEL_CLASSES[args.model_type]\n",
        "  #config = config_class.from_pretrained(args.model_name_or_path, cache_dir=None)\n",
        "\n",
        "  model = AutoModelWithLMHead.from_pretrained(\n",
        "      args.model_name_or_path,\n",
        "      from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
        "      config=config,\n",
        "      cache_dir=None,\n",
        "  )\n",
        "  model.to(args.device)\n",
        "  return model\n",
        "\n",
        "def set_seed(seed):\n",
        "  \"\"\"Set the random seed.\"\"\"\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if args.n_gpu > 0:\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "def do_perplexity_eval(args, model, data_file_path):\n",
        "  \"\"\"Computes the perplexity of the text in data_file_path according to the provided model.\"\"\"\n",
        "  set_seed(args.seed)\n",
        "\n",
        "  args.eval_data_file=data_file_path\n",
        "\n",
        "  #_, _, tokenizer_class = run_language_modeling.MODEL_CLASSES[args.model_type]\n",
        "  tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, cache_dir=None)\n",
        "\n",
        "  args.block_size = min(args.block_size, tokenizer.max_len)\n",
        "\n",
        "  result = run_language_modeling.evaluate(args, model, tokenizer, prefix=\"\")\n",
        "  return result\n",
        "\n",
        "\n",
        "def generate_samples(args, model, prompt_text):\n",
        "  \"\"\"Generating sampling for the provided prompt using the provided model.\"\"\"\n",
        "  set_seed(args.seed)\n",
        "\n",
        "  #_, _, tokenizer_class = run_language_modeling.MODEL_CLASSES[args.model_type]\n",
        "  tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, cache_dir=None)\n",
        "\n",
        "  requires_preprocessing = args.model_type in run_generation.PREPROCESSING_FUNCTIONS.keys()\n",
        "  encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n",
        "  encoded_prompt = encoded_prompt.to(args.device)\n",
        "\n",
        "  output_sequences = model.generate(\n",
        "      input_ids=encoded_prompt,\n",
        "      max_length=args.length + len(encoded_prompt[0]),\n",
        "      temperature=args.temperature,\n",
        "      top_k=args.k,\n",
        "      top_p=args.p,\n",
        "      no_repeat_ngram_size= args.no_repeat_ngram_size,\n",
        "      repetition_penalty=args.repetition_penalty,\n",
        "      do_sample=True,\n",
        "      num_return_sequences=args.num_return_sequences,\n",
        "  )\n",
        "\n",
        "  # Remove the batch dimension when returning multiple sequences\n",
        "  if len(output_sequences.shape) > 2:\n",
        "    output_sequences.squeeze_()\n",
        "\n",
        "  generated_sequences = []\n",
        "\n",
        "  for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
        "    generated_sequence = generated_sequence.tolist()\n",
        "\n",
        "    # Decode text\n",
        "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    # Remove all text after the stop token\n",
        "    text = text[: text.find(args.stop_token) if args.stop_token else None]\n",
        "\n",
        "    # Remove the excess text that was used for pre-processing\n",
        "    text = text[len(tokenizer.decode(encoded_prompt[0], clean_up_tokenization_spaces=True)) :]\n",
        "\n",
        "    # Add the prompt at the beginning of the sequence.\n",
        "    total_sequence = prompt_text + text\n",
        "\n",
        "    generated_sequences.append(total_sequence)\n",
        "\n",
        "  return generated_sequences\n",
        "\n",
        "import string\n",
        "from string import punctuation\n",
        "def get_data_grams(filename, n=6):\n",
        "    data_grams = set()\n",
        "    with open(filename,'r') as f:\n",
        "      jokes = [line.translate(str.maketrans('', '', string.punctuation)) for line in f if line.strip()!='']\n",
        "      for sequence in jokes:\n",
        "          sixgrams = ngrams(sequence.split(), n)\n",
        "          for gram in sixgrams:\n",
        "              data_grams.add(gram)\n",
        "    return data_grams, jokes\n",
        "\n",
        "\n",
        "\n",
        "#data_grams, jokes = get_data_grams(train_ON)\n",
        "\n",
        "\n",
        "def flatten(A):\n",
        "    rt = []\n",
        "    for i in A:\n",
        "        if isinstance(i,list): rt.extend(flatten(i))\n",
        "        else: rt.append(i)\n",
        "    return rt\n",
        "\n",
        "def classify_jokes(text, toxic_score=-5, joke_score=0.2,rest=''):\n",
        "  result = False\n",
        "  if text !='':\n",
        "    ans = predict_it(text,tokenizer,model)\n",
        "    if joke_score >ans[1]:\n",
        "      ans2 = toxic_it(text,tokenizer,toxic)\n",
        "      if toxic_score > ans2:\n",
        "        print(rest,text)\n",
        "        result = True\n",
        "        print()\n",
        "  return result \n",
        "\n",
        "def not_duplicates(sequences, data_grams, n=6, ngrams_sim=0.15):\n",
        "    if sequences== \"\" or sequences== \" \":\n",
        "      return False\n",
        "    sequences= sequences.translate(str.maketrans('', '', string.punctuation))\n",
        "    sixgrams = ngrams(sequences.split(), n)\n",
        "    results = []\n",
        "    for i, grams in enumerate(sixgrams):\n",
        "      result=True\n",
        "      if grams in data_grams:\n",
        "          result=False\n",
        "      results.append(result)\n",
        "    if len(results)==0:\n",
        "      return False\n",
        "    else:\n",
        "      return sum([1 if x else 0 for x in results])/len(results) > ngrams_sim\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def prepare_jokes(sequences,model_sentence):\n",
        "  sequence = flatten(sequences)\n",
        "  # \n",
        "  sequence_embeddings = model_sentence.encode(sequence)\n",
        "  return sequence,sequence_embeddings\n",
        "\n",
        "\n",
        "\n",
        "def write_jokes(model, args, prompts):\n",
        "  def strip_prompt(sequence, PROMPT):\n",
        "    sequences= []\n",
        "    PROMPT= PROMPT+' '\n",
        "    for seq in sequence:\n",
        "      seq= seq.strip(\"JOKE: \").strip(\"JOKES: \").strip(PROMPT)\n",
        "      sequences.append(seq)\n",
        "    return sequences\n",
        "  sequences=[]\n",
        "  for pr in prompts:\n",
        "      sequence = generate_samples(args, model, pr)\n",
        "      sequence = strip_prompt(sequence, pr)\n",
        "      sequences.extend(sequence)\n",
        "  return sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ku5-p-T5fhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# Set this to the checkpoint you want to use for generation, or to \"gpt2-medium\"\n",
        "# to generate with the pre-trained model without finetuning.\n",
        "%cd /content/\n",
        "blocks_location = '/content/blocks.txt'\n",
        "def get_blocks(file_name):\n",
        "  blocks=[]\n",
        "  buck.download_file('blocks.txt',file_name)\n",
        "  with open(file_name, 'r') as f:\n",
        "    for block in f.readlines():\n",
        "      blocks.append(block.strip('\\n').strip('\\r'))\n",
        "  return blocks\n",
        "blocks = get_blocks(blocks_location)\n",
        "def non_toxic(joke,blocks=blocks):\n",
        "  for block in blocks:\n",
        "    if block not in joke:\n",
        "      return True\n",
        "    else: \n",
        "      return False\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "print(\"Running on device: \", device)\n",
        "SEED = random.randint(0,20000)\n",
        "first_to_print = {}\n",
        "first_to_print['SEED'] = SEED \n",
        "first_to_print['TEMPERATURE'] =0.60\n",
        "first_to_print['K'] = 80\n",
        "first_to_print['p'] = .85\n",
        "\n",
        "args = DictToObj(collections.defaultdict(\n",
        "  model_name_or_path=CHECKPOINT_PATH,\n",
        "  output_dir=CHECKPOINT_PATH,\n",
        "  n_gpu=n_gpu,\n",
        "  mlm=False,\n",
        "  num_beams=5, \n",
        "  device=device,\n",
        "  model_type='gpt2-large',\n",
        "  seed=SEED,\n",
        "  stop_token='[cls]', # Set this if your dataset has a special word that indicates the end of a text.\n",
        "  temperature=0.60,  # temperature sampling. Set this to temperature=1.0 to not use temperature.\n",
        "  no_repeat_ngram_size= 8,\n",
        "  k=80,  # k for top-k sampling. Set this to k=0 to not use top-k.\n",
        "  p=.85,  # p for nucleus sampling. Set this to p=1.0 to not use nucleus sampling.\n",
        "  repetition_penalty=1.0,\n",
        "  length=100,  # Number of tokens to generate.\n",
        "  num_return_sequences=1,  # Number of independently computed samples to generate.\n",
        "))\n",
        "prompts = ['JOKE:',\"JOKE\",\"JOK\"]\n",
        "\n",
        "data_grams6, j = get_data_grams(train_ON, n=6)\n",
        "tokenizer=tokenizer()\n",
        "\n",
        "sequences = write_jokes(load_model(args), args, prompts) \n",
        "\n",
        "model=get_model(\"/content/joke1\",model_aws_dir='joke_class_torch_1' )\n",
        "\n",
        "toxic=get_model(\"/content/joke2\",model_aws_dir='toxicity/total_model.toxicity' )\n",
        "\n",
        "model_sentence, query_embeddings = get_embeddings(train_ON,buck)\n",
        "\n",
        "def get_jokes(joke, joke_embeddings, sb_sim=0.95, ngrams_sim=0.85,\n",
        "              toxic_score=-5, joke_score=0.5, \n",
        "              data_grams= data_grams6,\n",
        "              query_embeddings=query_embeddings ):\n",
        "  ngrams_sim= 1-ngrams_sim\n",
        "  joke_score = 1-joke_score\n",
        "  jokes=[]\n",
        "  for s,se  in zip(joke, joke_embeddings):\n",
        "\n",
        "    distances = scipy.spatial.distance.cdist([se], query_embeddings, \"cosine\")[0]\n",
        "    \n",
        "    if sorted(zip(range(len(distances)), distances), key=lambda x: x[1])[0][1] < sb_sim:\n",
        "        s_len= len(s.split())\n",
        "        if not_duplicates(s, data_grams, n=6,ngrams_sim=ngrams_sim):\n",
        "          if non_toxic(s):\n",
        "            if classify_jokes(s,toxic_score=toxic_score, joke_score=joke_score):\n",
        "              jokes.append(s)\n",
        "\n",
        "  return jokes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9dIyX0i9WG9",
        "colab_type": "text"
      },
      "source": [
        "## Test Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1UZBFcTTDO8",
        "colab_type": "code",
        "outputId": "01257887-cc74-4455-ff34-9839ffe34112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#buck.upload_file(blocks_location,'blocks.txt')\n",
        "joke, joke_embeddings = prepare_jokes(sequences,model_sentence)\n",
        "jokes =  get_jokes(joke, joke_embeddings )\n",
        "first_to_print['JOKES']=jokes\n",
        "first_to_print['Unfiltered']=joke\n",
        "file_name = 'JOke_first_Run'+\"_\"+str(random.randint(0,20000))+\".txt\"\n",
        "print(first_to_print, file=open(file_name, \"a\"))\n",
        "write_buck.upload_file(file_name,file_name)\n",
        "buck.upload_file(file_name,file_name)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 1/1 [00:00<00:00, 45.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Why do girls always get the short end of the stick? Because they are always asking for the long one.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPKKLKT35KUJ",
        "colab_type": "text"
      },
      "source": [
        "# Hall of Fame: \n",
        "\n",
        " Why did the construction worker get fired? He was caught digging up the yard  \n",
        " How do you catch a unique rabbit? Unique up on it \n",
        " \n",
        " What did the blind man say to the deaf man? See you next week.\n",
        "\n",
        "  I'm going to start a company that sells a product called \"No More Tears\" It's supposed to be a tear-free alternative to tear gas.\n",
        "\n",
        " What did the hipster say to the hipster who was eating his food? \"I'm not a fan of your food.\"\n",
        " \n",
        " I'm not saying that I'm a good dancer, but I'm pretty good at not falling.\n",
        "\n",
        "I want to die peacefully in my sleep. I don't want to wake up screaming.\n",
        "\n",
        "i hate people who take photographs of my pets they just take all my good pictures\n",
        "\n",
        "when the shoe store advertised for new employees they had a hard time getting foot traffic\n",
        "\n",
        "PUNS: the short order cook was short on time but overcookin\n",
        "PUNS: the inventor of the flashlight was a bright light\n",
        "\n",
        "PUNS: the last time i saw my dentist he was filling in for me"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lm-n8ngcjQV",
        "colab_type": "text"
      },
      "source": [
        "# HumorBot3000 Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdOwObH9EAE8",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "85786329-24e7-4858-9c74-fd51ddc757eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#@title # HumorBot 3000 \n",
        "#@markdown ## Welcome to HumorBot!  \n",
        "#@markdown ### Adjust the parameters below to generate jokes to your liking. When you are down simply hit the play button on the top left hand corner.  \n",
        "#@markdown #### Add a nickname to make your results unique. \n",
        "your_nickname = \"Just_looking\" #@param {type: 'string'} \n",
        "#@markdown #### Add your own joke setup, (ex. why did the chicken cross the road) or leave blank to use a random setup\n",
        "new_prompt ='' #@param {type: \"string\"}\n",
        "#@markdown #### Increasing the joke score will filter out more bad jokes \n",
        "JOKE_SCORE = 0.75 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "#@markdown #### k for top-k sampling. Set k=0 if you don't want to use top-k.\n",
        "\n",
        "TOP_K_SAMPLING=120  #@param \n",
        "#@markdown #### Set NUCLEUS_SAMPLING=1.0 to not use nucleus sampling.\n",
        "NUCLEUS_SAMPLING = 0.85 #@param {type:\"slider\", min:0.0, max:1.0, step:0.05}\n",
        "#@markdown #### number of beams per iteration.\n",
        "NUMBER_BEAMS=5 #@param {type: 'integer'}\n",
        "#@markdown repetition penalty must be greater than one \n",
        "repetition_penalty=1.0 #@param {type: 'number'} \n",
        "#@markdown #### Increasing the temperature make the reponses more non sequitor. To stop using temperature, set temperature=1.0 .\n",
        "TEMPERATURE = 0.79 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01} \n",
        "#@markdown ### More Stuff to play with: \n",
        "#@markdown #### Set SEED to 0 to not use seed. \n",
        "SEED=0 #@param \n",
        "#@markdown #### Decrease Siamese Bert Similarity to remove duplicates. \n",
        "SIAMESE_BERT_SIMILARITY = 0.95 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01} \n",
        "#@markdown #### Decrease Ngram_similarity to remove duplicates. \n",
        "NGRAMS_SIMILARITY = 0.85 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "#@markdown #### Warning Increase the toxivity score will generate foul jokes \n",
        "TOXICITY_SCORE = -5.8 #@param {type:\"slider\", min:-10.0, max:10.0, step:0.1}\n",
        "\n",
        "import random\n",
        "if SEED==0:\n",
        "  SEED= random.randint(0,10000)\n",
        "arguments = collections.defaultdict(\n",
        "  model_name_or_path=CHECKPOINT_PATH,\n",
        "  output_dir=CHECKPOINT_PATH,\n",
        "  p=NUCLEUS_SAMPLING ,n_gpu=n_gpu,  k=TOP_K_SAMPLING ,mlm=False,\n",
        "  num_beams=NUMBER_BEAMS ,device=device, seed=SEED,model_type='gpt2-large',\n",
        "  temperature=TEMPERATURE, no_repeat_ngram_size=8,stop_token='[cls]', \n",
        "  repetition_penalty=1.0\n",
        "  ,length=100,  # Number of tokens to generate.\n",
        "  num_return_sequences=40,  # Number of independently computed samples to generate.\n",
        "\n",
        ")\n",
        "args = DictToObj(arguments)\n",
        "\n",
        "\n",
        "prompts = ['JOKE:','JOKE','JOKES:',]\n",
        "if new_prompt!='':\n",
        "  prompts.append('JOKE: '+new_prompt)\n",
        "\n",
        "\n",
        "names_names = [[SIAMESE_BERT_SIMILARITY,'SIAMESE_BERT_SIMILARITY'], \n",
        "               [NGRAMS_SIMILARITY,'NGRAMS_SIMILARITY'], [TOXICITY_SCORE,'TOXICITY_SCORE'], \n",
        "               [JOKE_SCORE,'JOKE_SCORE'],[your_nickname,'your_nickname'], \n",
        "               [new_prompt,'new_prompt'],[prompts,'prompts'],\n",
        "               [TOP_K_SAMPLING,'TOP_K_SAMPLING'],\n",
        "               [NUCLEUS_SAMPLING,'NUCLEUS_SAMPLING'], \n",
        "               [NUMBER_BEAMS,'NUMBER_BEAMS'],[repetition_penalty,'repetition_penalty'],\n",
        "               [TEMPERATURE,'TEMPERATURE'], [SEED,'SEED'],\n",
        "               [SIAMESE_BERT_SIMILARITY,'SIAMESE_BERT_SIMILARITY'],\n",
        "               [NGRAMS_SIMILARITY, 'NGRAMS_SIMILARITY'], \n",
        "               [TOXICITY_SCORE, 'TOXICITY_SCORE'],[JOKE_SCORE,'JOKE_SCORE']]\n",
        "arguments_to_print={}\n",
        "for name in names_names:\n",
        "  arguments_to_print[name[1]]=name[0] \n",
        "#print(arguments_to_print)\n",
        "sequences = write_jokes(load_model(args), args, prompts) \n",
        "#model=get_model(\"/content/joke1\" )\n",
        "#toxic=get_model(\"/content/joke2\" )\n",
        "raw_jokes, joke_embeddings = prepare_jokes(sequences,model_sentence)\n",
        "jokes =  get_jokes(raw_jokes, joke_embeddings,\n",
        "          sb_sim=SIAMESE_BERT_SIMILARITY, \n",
        "          ngrams_sim=NGRAMS_SIMILARITY,\n",
        "          toxic_score=TOXICITY_SCORE, joke_score=JOKE_SCORE )\n",
        "arguments_to_print['JOKES']=jokes\n",
        "arguments_to_print['Unfiltered']=joke\n",
        "file_name = your_nickname+\"_\"+str(random.randint(0,20000))+\".txt\"\n",
        "print(arguments_to_print, file=open(file_name, \"a\"))\n",
        "write_buck.upload_file(file_name,file_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 15/15 [00:00<00:00, 72.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Why is it so hard to eat out in France? Because of the cheese.\n",
            "\n",
            " How do you make a good pizza? You don't, you just throw it out and ask for another one.\n",
            "\n",
            " What do you call a man who can tell you the weather? A weatherman.\n",
            "\n",
            " What do you call a cow that's been on a roof for a while? Lean beef.\n",
            "\n",
            " What do you call a ghost that's had too many coffees? A ghost coffee.\n",
            "\n",
            " Why is it so hard to eat out with the blind? They don't know what to do with the forks.\n",
            "\n",
            " What do you call a bird that doesn't know what it's doing? A falcon!\n",
            "\n",
            " *eats a slice of pizza* *eats a slice of pizza again* *eats another slice of pizza* *eats another slice of Pizza*\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1q2Ic8i183X",
        "colab_type": "text"
      },
      "source": [
        "# Tell me a Joke!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMYCKd-gCALV",
        "colab_type": "code",
        "outputId": "5af23aed-7b68-4df1-d0aa-52635fccd06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "\n",
        "from gtts import gTTS #Import Google Text to Speech\n",
        "\n",
        "from IPython.display import Audio #Import Audio method from IPython's Display Class\n",
        "tts = gTTS(jokes[0]) #Provide the string to convert to speech\n",
        "tts.save('1.wav') #save the string converted to speech as a .wav file\n",
        "sound_file = '1.wav'\n",
        "print(\"Type True if you want a verbal joke\")\n",
        "# if input():\n",
        "#   print(\"sucess\")\n",
        "Audio(sound_file) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type True if you want a verbal joke\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "                <audio controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktPN40rWaYlH",
        "colab_type": "text"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8QI2CPHG_c-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @article{Wolf2019HuggingFacesTS,\n",
        "#   title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},\n",
        "#   author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},\n",
        "#   journal={ArXiv},\n",
        "#   year={2019},\n",
        "#   volume={abs/1910.03771}\n",
        "# }\n",
        "# @article{radford2019language,\n",
        "#   title={Language Models are Unsupervised Multitask Learners},\n",
        "#   author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},\n",
        "#   year={2019}\n",
        "# }\n",
        "# @ARTICLE\n",
        "# {humorDetection2019,\n",
        "#   title={Humor Detection: A Transformer gets the Last Laugh},\n",
        "#   author={Weller, Orion and Seppi, Kevin},\n",
        "#   journal={\"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\"},\n",
        "#   month=Nov,\n",
        "#   year = \"2019\",\n",
        "# }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UclbE4zb-VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}