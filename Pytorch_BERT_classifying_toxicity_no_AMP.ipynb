{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Pytorch_BERT_classifying_toxicity_no_AMP",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "179cfb2073914e89a023c0f27d483d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e2998cb1cea4d4597df0650ab9fcff6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f77563d38e3d429d8f6405891d40df80",
              "IPY_MODEL_31719bc5ae3f44d099aa82377bce23ad"
            ]
          }
        },
        "2e2998cb1cea4d4597df0650ab9fcff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f77563d38e3d429d8f6405891d40df80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_da2fe2fb6a23403bbee9edafae0b6a86",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4d7ad398155409db8f25290912d1301"
          }
        },
        "31719bc5ae3f44d099aa82377bce23ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_087385e286dd4685bd24e02110769869",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:27&lt;00:00, 13.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67619fb18d784e15b47f7c0bdd68344b"
          }
        },
        "da2fe2fb6a23403bbee9edafae0b6a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4d7ad398155409db8f25290912d1301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "087385e286dd4685bd24e02110769869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67619fb18d784e15b47f7c0bdd68344b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ce67cf68ce7425d8b807e74cc88c8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edade261c194467f805bab8720e4a622",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d49e9a0569a742e283e5273bbf4a8743",
              "IPY_MODEL_19fcdde59ea84c7a8a1900c484932ce1"
            ]
          }
        },
        "edade261c194467f805bab8720e4a622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d49e9a0569a742e283e5273bbf4a8743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81a9bcb4b82f4e84a7b6841ad21d30e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c535c14a8bc64f89b922732f39428c61"
          }
        },
        "19fcdde59ea84c7a8a1900c484932ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3a8a161419f44ed84c4771c8912cc88",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:08&lt;00:00, 51.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5de5b048ba8b4db499ed61aaa5d2eb9c"
          }
        },
        "81a9bcb4b82f4e84a7b6841ad21d30e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c535c14a8bc64f89b922732f39428c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3a8a161419f44ed84c4771c8912cc88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5de5b048ba8b4db499ed61aaa5d2eb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "759869bac61d4627a3b49505f16dc56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5869025456e0485397a5874655fab461",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d177d7e603d545bba818870f75f0754a",
              "IPY_MODEL_8f4d1cd72f584148b1d00c8a4bab04cf"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataSci-rigo/hum0rB0T3000/blob/master/Pytorch_BERT_classifying_toxicity_no_AMP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldZbZJphjAyR",
        "colab_type": "text"
      },
      "source": [
        "Now we will continue on the [Conversation AI](https://conversationai.github.io/) dataset seen in [week 4 homework and lab](https://github.com/MIDS-scaling-up/v2/tree/master/week04). \n",
        "We shall use a version of pytorch BERT for classifying comments found at [https://github.com/huggingface/pytorch-pretrained-BERT](https://github.com/huggingface/pytorch-pretrained-BERT).  \n",
        "\n",
        "This script relies heavily on an existing [Kaggle kernel](https://www.kaggle.com/yuval6967/toxic-bert-plain-vanila) from [yuval r](https://www.kaggle.com/yuval6967). \n",
        "  \n",
        "*Disclaimer: the dataset used contains text that may be considered profane, vulgar, or offensive.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Fvb8HhijTrL",
        "colab_type": "code",
        "outputId": "d8b4ea0e-cd32-499c-8677-c7b8a5c29204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "export CUDA_HOME=/usr/local/cuda-10.1\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -r ./apex/requirements.txt\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing setup.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkdRpAmCjcot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "#!sh setup.sh\n",
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw0WUJhejiaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "import os\n",
        "os.chdir('transformers')\n",
        "\n",
        "!python -m pip install .\n",
        "!python -m pip install -r ./examples/requirements.txt\n",
        "os.chdir('examples')\n",
        "!python -m pip install dict_to_obj "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ukfmgetjAyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import warnings\n",
        "warnings.filterwarnings(action='once')\n",
        "import pickle\n",
        "#from apex import amp\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClGEazXsjAyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's activate CUDA for GPU based operations\n",
        "device=torch.device('cuda')\n",
        "# In bert we need all inputs to have the same length, we will use the first 220 characters. \n",
        "!mkdir /content/workingdir\n",
        "MAX_SEQUENCE_LENGTH = 220\n",
        "SEED = 1234\n",
        "# We shall run a single epoch (ie. one pass over the data)\n",
        "EPOCHS = 1 #2 #EPOCHS\n",
        "PATH = '/content/' # /root/v2/week06/hw\"\n",
        "DATA_DIR = os.path.join(PATH, \"data\")\n",
        "WORK_DIR = os.path.join(PATH, \"workingdir\")\n",
        "\n",
        "# Validation and training sizes are here. \n",
        "\n",
        "train_size= 1000000 #10000 # \n",
        "valid_size=  500000 #5000  #\n",
        "\n",
        "BERT_MODEL = 'bert-base-uncased'\n",
        "CACHE_DIR = 'cache/'\n",
        "!mkdir {CACHE_DIR}\n",
        "num_labels = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75V_nMcTnOVI",
        "colab_type": "code",
        "outputId": "ba583fa7-d1a3-4689-d7eb-c55262916592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "# try:\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers import (WEIGHTS_NAME, BertConfig,BertForSequenceClassification, BertTokenizer,)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "ALL_MODELS = sum((tuple(conf.pretrained_config_archive_map.keys()) for conf in (BertConfig, )), ())\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer)}\n",
        "device = torch.device(\"cuda\")\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
            "  return f(*args, **kwds)\n",
            "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
            "  return f(*args, **kwds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBRM98fRvo7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import boto3\n",
        "s3r = boto3.resource('s3', aws_access_key_id='AKIA32S7UTDXTR5GRXX6',\n",
        "    aws_secret_access_key='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')\n",
        "buck = s3r.Bucket('humorbot3000')\n",
        "\n",
        "buck.download_file('train_all_toxic.csv', '/content/train_all_toxic.csv')\n",
        "buck.download_file('sequences_toxic.npy', '/content/sequences_toxic.npy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wclNLk_MjAzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_all = pd.read_csv('/content/train_all_toxic.csv')\n",
        "sequences = np.load('/content/sequences_toxic.npy',allow_pickle=True)\n",
        "train_all['target']=(train_all['target']>=0.5).astype(float)\n",
        "# Training data - sentences\n",
        "X = sequences[:train_size] \n",
        "# Target - the toxicity. \n",
        "y = train_all[['target']].values[:train_size]\n",
        "X_val = sequences[train_size:]                \n",
        "y_val = train_all[['target']].values[train_size:]\n",
        "test_df=train_all.tail(valid_size).copy()\n",
        "train_df=train_all.head(train_size)\n",
        "# Training data creations\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.float))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xogNfsTMjAzU",
        "colab_type": "code",
        "outputId": "85d79c9a-1e65-4a25-facc-5b4b44385c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "179cfb2073914e89a023c0f27d483d14",
            "2e2998cb1cea4d4597df0650ab9fcff6",
            "f77563d38e3d429d8f6405891d40df80",
            "31719bc5ae3f44d099aa82377bce23ad",
            "da2fe2fb6a23403bbee9edafae0b6a86",
            "a4d7ad398155409db8f25290912d1301",
            "087385e286dd4685bd24e02110769869",
            "67619fb18d784e15b47f7c0bdd68344b",
            "2ce67cf68ce7425d8b807e74cc88c8e1",
            "edade261c194467f805bab8720e4a622",
            "d49e9a0569a742e283e5273bbf4a8743",
            "19fcdde59ea84c7a8a1900c484932ce1",
            "81a9bcb4b82f4e84a7b6841ad21d30e5",
            "c535c14a8bc64f89b922732f39428c61",
            "e3a8a161419f44ed84c4771c8912cc88",
            "5de5b048ba8b4db499ed61aaa5d2eb9c"
          ]
        }
      },
      "source": [
        "%%time\n",
        "#SEED=561\n",
        "\n",
        "lr=2e-5\n",
        "batch_size = 32 #32\n",
        "accumulation_steps=2\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "print(WORK_DIR)\n",
        "\n",
        "y_targets=1 #1 column\n",
        "model = BertForSequenceClassification.from_pretrained(BERT_MODEL,cache_dir=None,num_labels=y_targets)\n",
        "model.zero_grad() ###initialize gradients\n",
        "model = model.to(device) ##set device to cuda  ##device='cuda:0', requires_grad=True\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "#print(param_optimizer)\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "train = train_dataset\n",
        "\n",
        "num_train_optimization_steps = int(len(train_dataset)/batch_size/accumulation_steps)\n",
        "\n",
        "# optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "#                      lr=lr,\n",
        "#                      warmup=0.05,\n",
        "#                      t_total=num_train_optimization_steps)\n",
        "\n",
        "#model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=1) ##initialize optimizer with APEX as amp\n",
        "# num_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n",
        "warmup_proportion = 0.05\n",
        "num_warmup_steps = int(warmup_proportion*num_train_optimization_steps)\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=False)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps,\n",
        "                                            num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
        "\n",
        "model=model.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/workingdir\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "179cfb2073914e89a023c0f27d483d14",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ce67cf68ce7425d8b807e74cc88c8e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 13.4 s, sys: 2.42 s, total: 15.8 s\n",
            "Wall time: 27.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeM1Z-nZjAzY",
        "colab_type": "code",
        "outputId": "71140c79-8c35-4591-9704-7be219b75dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "759869bac61d4627a3b49505f16dc56e",
            "5869025456e0485397a5874655fab461",
            "d177d7e603d545bba818870f75f0754a",
            "8f4d1cd72f584148b1d00c8a4bab04cf"
          ]
        }
      },
      "source": [
        "#%%time\n",
        "#model=model.train()\n",
        "import tqdm.notebook as tqdm\n",
        "lossf=None\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "tk0 = tqdm.tqdm(enumerate(train_loader),total=len(train_loader),leave=False)\n",
        "optimizer.zero_grad()   # Bug fix - thanks to @chinhuic\n",
        "for i,(x_batch, y_batch) in tk0:\n",
        "\n",
        "    y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        "    #print(y_pred.shape)\n",
        "    #print(y_batch.shape)\n",
        "    loss =  F.binary_cross_entropy_with_logits(y_pred[0],y_batch.to(device))\n",
        "    loss.backward()\n",
        "    # with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "    #     scaled_loss.backward()\n",
        "    if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
        "        optimizer.step()                            # Now we can do an optimizer step\n",
        "        optimizer.zero_grad()\n",
        "    if lossf:\n",
        "        lossf = 0.98*lossf+0.02*loss.item()\n",
        "    else:\n",
        "        lossf = loss.item()\n",
        "    tk0.set_postfix(loss = lossf)\n",
        "torch.save(model.state_dict(), \"/content/output_dict_no_amp_toxicity\")\n",
        "buck.upload_file(\"/content/output_dict_no_amp_toxicity\", 'output_dict_no_amp_toxicity')\n",
        "torch.save(model, \"/content/output_full_no_amp_toxicity.model\")\n",
        "buck.upload_file(\"/content/output_full_no_amp_toxicity.model\", \"output_full_no_amp_toxicity.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "759869bac61d4627a3b49505f16dc56e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=31250), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF4KZhCGjAzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.eval()\n",
        "valid_preds = np.zeros((len(X_val)))\n",
        "valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n",
        "\n",
        "tk0 = tqdm_notebook(valid_loader)\n",
        "for i,(x_batch,)  in enumerate(tk0):\n",
        "    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n",
        "    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cNBcOJ_jAzh",
        "colab_type": "text"
      },
      "source": [
        "**6)**  \n",
        "**In the yuval's kernel he get a metric based on the metric for the jigsaw competition - it is quite complicated. Instead, we would like you to measure the `AUC`, similar to how you did in homework 04. You can compare the results to HW04**  \n",
        "*A tip, if your score is lower than homework 04 something is wrong....*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "aSHUEOSOjAzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('AUC score : {:.5f}'.format(roc_auc_score(y_val, valid_preds)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FebOU0dtjAzl",
        "colab_type": "text"
      },
      "source": [
        "AUC score : 0.92835 for learning rate=2e-5, batch_size = 32, accumulation_steps=2"
      ]
    }
  ]
}